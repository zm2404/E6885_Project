{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BlI8iHgEP1wB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fab13ab-d3f2-4e72-c4a3-10a7a03823f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_agents in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (0.5.0)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf_agents) (9.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (4.5.0)\n",
            "Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (2.1.3)\n",
            "Requirement already satisfied: tensorflow-probability~=0.23.0 in /usr/local/lib/python3.10/dist-packages (from tf_agents) (0.23.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf_agents) (0.0.8)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.23.0->tf_agents) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.23.0->tf_agents) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.23.0->tf_agents) (0.1.8)\n",
            "Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (9.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (4.5.0)\n",
            "Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.1.3)\n",
            "Requirement already satisfied: tensorflow-probability~=0.23.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: rlds in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: dm-reverb~=0.14.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.14.0)\n",
            "Requirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.14.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.14.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.23.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-agents[reverb]) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker->dm-reverb~=0.14.0->tf-agents[reverb]) (5.9.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tf_agents\n",
        "!pip install tf-agents[reverb]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CLWWFFWwP-Fk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tf_agents\n",
        "import reverb\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.utils import common\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import epsilon_greedy_policy\n",
        "from tf_agents.policies import policy_saver\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/E6885_Project')\n",
        "import SortWaterEnv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.version.VERSION"
      ],
      "metadata": {
        "id": "S7-5FyITqOTK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f4ee6e22-e153-49ca-92e0-2e577969a15d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "meuuIXmuQLEW"
      },
      "outputs": [],
      "source": [
        "num_iterations = 100000        #\n",
        "\n",
        "initial_collect_steps = 100     #\n",
        "collect_steps_per_iteration = 10#2#1   #\n",
        "replay_buffer_max_length = 100000  #\n",
        "\n",
        "batch_size = 64            #\n",
        "learning_rate = 1e-3        #\n",
        "log_interval = 200          #\n",
        "\n",
        "num_eval_episodes = 100        #\n",
        "eval_interval = 200#500#1000        #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_Be0fVlSQM1w"
      },
      "outputs": [],
      "source": [
        "############# create training and evaluation environment #############\n",
        "num_bottles = 5\n",
        "water_level = 4\n",
        "env = SortWaterEnv.WaterSortEnv(num_bottles=num_bottles, water_level=water_level, random_init=True)\n",
        "train_py_env = SortWaterEnv.WaterSortEnv(num_bottles=num_bottles, water_level=water_level, random_init=True)\n",
        "eval_py_env = SortWaterEnv.WaterSortEnv(num_bottles=num_bottles, water_level=water_level, random_init=True)\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KSsS5sENQQa2"
      },
      "outputs": [],
      "source": [
        "############ create a DQN agent ############\n",
        "fc_layer_params = (100, 50)\n",
        "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
        "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jddUDIr2QSTO"
      },
      "outputs": [],
      "source": [
        "# Customized Q netword\n",
        "class MaskedQNetwork(q_network.QNetwork):\n",
        "  def __init__(self, input_tensor_spec, action_spec, fc_layer_params=(100,), **kwargs):\n",
        "    # 从 input_tensor_spec 元组中提取观察值规格\n",
        "    observation_spec = input_tensor_spec[0]\n",
        "\n",
        "    # 调用基类的构造函数以构建网络\n",
        "    super(MaskedQNetwork, self).__init__(observation_spec, action_spec, fc_layer_params=fc_layer_params, **kwargs)\n",
        "\n",
        "  def call(self, observation, step_type=None, network_state=(), training=False):\n",
        "    # 直接调用父类的 call 方法，处理观察值\n",
        "    return super(MaskedQNetwork, self).call(\n",
        "        observation, step_type, network_state, training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rqi6-5F7RG-n"
      },
      "outputs": [],
      "source": [
        "observation_spec = train_env.observation_spec()\n",
        "action_spec = train_env.action_spec()\n",
        "\n",
        "# create Q-network\n",
        "q_net = MaskedQNetwork(\n",
        "    (observation_spec['observation'], observation_spec['action_mask']),\n",
        "    action_spec,\n",
        "    fc_layer_params=fc_layer_params\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jMoFiViiC7NV"
      },
      "outputs": [],
      "source": [
        "def observation_and_action_constraint_splitter(obs):\n",
        "\treturn obs['observation'], obs['action_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qI_nu75uRRqe"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter,\n",
        "    observation_and_action_constraint_splitter=observation_and_action_constraint_splitter\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1AhbI3ZfbFpm"
      },
      "outputs": [],
      "source": [
        "# an example, just to show what policies are used during evaluation and collecting\n",
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sH_fIsadbICb"
      },
      "outputs": [],
      "source": [
        "# an example, just show how to create epsilon_greedy_policy. Not to be used\n",
        "base_policy = agent.policy\n",
        "epsilon = 0.1  # 例如，使用 0.1 作为 epsilon 值\n",
        "epsilon_greedy_policy = epsilon_greedy_policy.EpsilonGreedyPolicy(base_policy, epsilon=epsilon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z9kV-ZLvbJVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4878db73-0431-4c84-a78c-e8d27bcc0aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeStep(\n",
            "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>,\n",
            " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
            " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
            " 'observation': {'observation': <tf.Tensor: shape=(1, 5, 4), dtype=int32, numpy=\n",
            "array([[[1, 2, 1, 2],\n",
            "        [0, 0, 0, 0],\n",
            "        [3, 3, 3, 2],\n",
            "        [3, 1, 2, 1],\n",
            "        [0, 0, 0, 0]]], dtype=int32)>,\n",
            "                 'action_mask': <tf.Tensor: shape=(1, 20), dtype=bool, numpy=\n",
            "array([[ True, False, False,  True, False, False, False, False, False,\n",
            "         True, False,  True, False,  True, False,  True, False, False,\n",
            "        False, False]])>}})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>, state=(), info=())"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# example of greedy policy choosing action\n",
        "example_py_env = SortWaterEnv.WaterSortEnv(num_bottles=num_bottles, water_level=water_level, random_init=True)\n",
        "example_env = tf_py_environment.TFPyEnvironment(example_py_env)\n",
        "time_step = example_env.reset()\n",
        "print(time_step)\n",
        "epsilon_greedy_policy.action(time_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_0MKdny2bK-Q"
      },
      "outputs": [],
      "source": [
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZuqXjbWrbMQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68114479-9b21-4e7f-b7c6-62f860a84a26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.94"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# an example\n",
        "compute_avg_return(eval_env, epsilon_greedy_policy, num_eval_episodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CQzc5_e4bP53"
      },
      "outputs": [],
      "source": [
        "################# Replay buffer #################\n",
        "table_name = 'uniform_table'\n",
        "replay_buffer_signature = tensor_spec.from_spec(\n",
        "      agent.collect_data_spec)\n",
        "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
        "    replay_buffer_signature)\n",
        "\n",
        "table = reverb.Table(\n",
        "    table_name,\n",
        "    max_size=replay_buffer_max_length,\n",
        "    sampler=reverb.selectors.Uniform(),\n",
        "    remover=reverb.selectors.Fifo(),\n",
        "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
        "    signature=replay_buffer_signature)\n",
        "\n",
        "reverb_server = reverb.Server([table])\n",
        "\n",
        "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
        "    agent.collect_data_spec,\n",
        "    table_name=table_name,\n",
        "    sequence_length=2,\n",
        "    local_server=reverb_server)\n",
        "\n",
        "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
        "  replay_buffer.py_client,\n",
        "  table_name,\n",
        "  sequence_length=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0XbLZjCtb__-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc4bd93-8219-4e3e-f756-ef374730d6c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_TupleWrapper(Trajectory(\n",
              "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
              " 'observation': DictWrapper({'observation': BoundedTensorSpec(shape=(5, 4), dtype=tf.int32, name='observation', minimum=array(0, dtype=int32), maximum=array(3, dtype=int32)), 'action_mask': TensorSpec(shape=(20,), dtype=tf.bool, name='action_mask')}),\n",
              " 'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(19, dtype=int32)),\n",
              " 'policy_info': (),\n",
              " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
              " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
              " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))}))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "agent.collect_data_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TeCbnlphcesk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d04d341-e2ee-47c3-d22c-2b3d844e1ad1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('step_type',\n",
              " 'observation',\n",
              " 'action',\n",
              " 'policy_info',\n",
              " 'next_step_type',\n",
              " 'reward',\n",
              " 'discount')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "agent.collect_data_spec._fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "X3Hv74IhckJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ee2b54-e092-458c-d89f-c20dce746109"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TimeStep(\n",
              " {'step_type': array(1, dtype=int32),\n",
              "  'reward': array(0., dtype=float32),\n",
              "  'discount': array(1., dtype=float32),\n",
              "  'observation': {'observation': array([[0, 0, 0, 0],\n",
              "        [2, 2, 3, 1],\n",
              "        [3, 1, 3, 1],\n",
              "        [1, 0, 0, 0],\n",
              "        [2, 2, 3, 0]], dtype=int32),\n",
              "                  'action_mask': array([False, False, False, False,  True, False,  True, False,  True,\n",
              "        False,  True, False,  True, False, False, False,  True, False,\n",
              "        False, False])}}),\n",
              " ())"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# an example.\n",
        "py_driver.PyDriver(\n",
        "    train_py_env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      epsilon_greedy_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=initial_collect_steps).run(train_py_env.reset())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.get_state()"
      ],
      "metadata": {
        "id": "ohhyBZROzNh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ad1318-c7f0-489a-982d-f95ed676a31f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'observation': array([[1, 1, 3, 2],\n",
              "        [0, 0, 0, 0],\n",
              "        [3, 3, 1, 3],\n",
              "        [0, 0, 0, 0],\n",
              "        [2, 1, 2, 2]], dtype=int32),\n",
              " 'action_mask': array([ True, False,  True, False, False, False, False, False, False,\n",
              "         True,  True, False, False, False, False, False, False,  True,\n",
              "        False,  True])}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nh7SqXgkdYNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9efaa85-0e51-4c40-b8b9-bf7bb290ffc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(Trajectory(\n",
              "{'step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
              " 'observation': DictWrapper({'observation': TensorSpec(shape=(64, 2, 5, 4), dtype=tf.int32, name=None), 'action_mask': TensorSpec(shape=(64, 2, 20), dtype=tf.bool, name=None)}),\n",
              " 'action': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
              " 'policy_info': (),\n",
              " 'next_step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
              " 'reward': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None),\n",
              " 'discount': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None)}), SampleInfo(key=TensorSpec(shape=(64, 2), dtype=tf.uint64, name=None), probability=TensorSpec(shape=(64, 2), dtype=tf.float64, name=None), table_size=TensorSpec(shape=(64, 2), dtype=tf.int64, name=None), priority=TensorSpec(shape=(64, 2), dtype=tf.float64, name=None), times_sampled=TensorSpec(shape=(64, 2), dtype=tf.int32, name=None)))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Mp0I59Vwd11M"
      },
      "outputs": [],
      "source": [
        "iterator = iter(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pqBPd98nu52O"
      },
      "outputs": [],
      "source": [
        "# demo: only 1 episode\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  %%time\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step.\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "# Reset the environment.\n",
        "time_step = train_py_env.reset()\n",
        "\n",
        "# Create a driver to collect experience.\n",
        "collect_driver = py_driver.PyDriver(\n",
        "    train_py_env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      agent.collect_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=collect_steps_per_iteration)\n",
        "\n",
        "######### early stopping ##########\n",
        "# set save direction\n",
        "tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n",
        "# checkpointer\n",
        "# checkpoint_dir = os.path.join(tempdir, 'checkpoint')\n",
        "# train_checkpointer = common.Checkpointer(\n",
        "#     ckpt_dir=checkpoint_dir,\n",
        "#     max_to_keep=1,\n",
        "#     agent=agent,\n",
        "#     policy=agent.policy,\n",
        "#     replay_buffer=replay_buffer,\n",
        "#     global_step=train_step_counter\n",
        "# )\n",
        "# policy saver\n",
        "policy_dir = os.path.join(tempdir, 'policy')\n",
        "tf_policy_saver = policy_saver.PolicySaver(agent.policy)\n",
        "\n",
        "# some threshold\n",
        "#best_avg_return = -float('inf')\n",
        "best_avg_return = 0.7\n",
        "no_improvement_steps = 0\n",
        "early_stopping_threshold = 10\n",
        "earlystop = False\n",
        "iter_thres = 10000\n",
        "######### early stopping ##########\n",
        "\n",
        "\n",
        "iter_count = 0\n",
        "for _ in range(num_iterations):\n",
        "  iter_count += 1\n",
        "  #print('iter_count: ',iter_count)\n",
        "  # Collect a few steps and save to the replay buffer.\n",
        "  time_step, _ = collect_driver.run(time_step)\n",
        "\n",
        "  # Sample a batch of data from the buffer and update the agent's network.\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "\n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "    returns.append(avg_return)\n",
        "\n",
        "  ######### early stopping ##########\n",
        "    if avg_return > best_avg_return:\n",
        "      earlystop = True\n",
        "    if (avg_return > best_avg_return) and earlystop and (iter_count > iter_thres):\n",
        "      best_avg_return = avg_return\n",
        "      no_improvement_steps = 0\n",
        "      tf_policy_saver.save(policy_dir)  # save policy\n",
        "    elif earlystop and (iter_count > iter_thres):\n",
        "      no_improvement_steps += 0\n",
        "    print(\"no_improvement_steps: \",no_improvement_steps)\n",
        "  if no_improvement_steps >= early_stopping_threshold:\n",
        "    print(\"No improvement for {0} steps. Early stopping...\".format(no_improvement_steps))\n",
        "    break\n",
        "  ######### early stopping ##########"
      ],
      "metadata": {
        "id": "35k0m3HtqQyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b200fa0f-76c5-494c-bca3-bbc3a528e8fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.foldr(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 0.9021737575531006\n",
            "step = 200: Average Return = -0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 400: loss = 0.14679375290870667\n",
            "step = 400: Average Return = -0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 600: loss = 0.07425868511199951\n",
            "step = 600: Average Return = 0.019999999552965164\n",
            "no_improvement_steps:  0\n",
            "step = 800: loss = 0.15042197704315186\n",
            "step = 800: Average Return = -0.07999999821186066\n",
            "no_improvement_steps:  0\n",
            "step = 1000: loss = 0.11257894337177277\n",
            "step = 1000: Average Return = 0.25999999046325684\n",
            "no_improvement_steps:  0\n",
            "step = 1200: loss = 0.12072981148958206\n",
            "step = 1200: Average Return = -0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 1400: loss = 0.062223341315984726\n",
            "step = 1400: Average Return = -0.23999999463558197\n",
            "no_improvement_steps:  0\n",
            "step = 1600: loss = 0.10009774565696716\n",
            "step = 1600: Average Return = 0.05999999865889549\n",
            "no_improvement_steps:  0\n",
            "step = 1800: loss = 0.20167005062103271\n",
            "step = 1800: Average Return = 0.14000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 2000: loss = 0.10711528360843658\n",
            "step = 2000: Average Return = 0.3400000035762787\n",
            "no_improvement_steps:  0\n",
            "step = 2200: loss = 0.1874024122953415\n",
            "step = 2200: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 2400: loss = 0.01822228543460369\n",
            "step = 2400: Average Return = 0.2199999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 2600: loss = 0.10217316448688507\n",
            "step = 2600: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 2800: loss = 0.09967108070850372\n",
            "step = 2800: Average Return = 0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 3000: loss = 0.10737718641757965\n",
            "step = 3000: Average Return = 0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 3200: loss = 0.047609467059373856\n",
            "step = 3200: Average Return = 0.2199999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 3400: loss = 0.10942001640796661\n",
            "step = 3400: Average Return = 0.23999999463558197\n",
            "no_improvement_steps:  0\n",
            "step = 3600: loss = 0.17694833874702454\n",
            "step = 3600: Average Return = 0.2800000011920929\n",
            "no_improvement_steps:  0\n",
            "step = 3800: loss = 0.05958571285009384\n",
            "step = 3800: Average Return = -0.23999999463558197\n",
            "no_improvement_steps:  0\n",
            "step = 4000: loss = 0.05761267989873886\n",
            "step = 4000: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 4200: loss = 0.015470493584871292\n",
            "step = 4200: Average Return = 0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 4400: loss = 0.09453245997428894\n",
            "step = 4400: Average Return = 0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 4600: loss = 0.04065512865781784\n",
            "step = 4600: Average Return = 0.05999999865889549\n",
            "no_improvement_steps:  0\n",
            "step = 4800: loss = 0.21259349584579468\n",
            "step = 4800: Average Return = 0.10000000149011612\n",
            "no_improvement_steps:  0\n",
            "step = 5000: loss = 0.1028696745634079\n",
            "step = 5000: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 5200: loss = 0.08036049455404282\n",
            "step = 5200: Average Return = 0.2199999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 5400: loss = 0.3403592109680176\n",
            "step = 5400: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 5600: loss = 0.10873037576675415\n",
            "step = 5600: Average Return = 0.3400000035762787\n",
            "no_improvement_steps:  0\n",
            "step = 5800: loss = 0.21286456286907196\n",
            "step = 5800: Average Return = 0.03999999910593033\n",
            "no_improvement_steps:  0\n",
            "step = 6000: loss = 0.11538898944854736\n",
            "step = 6000: Average Return = 0.10000000149011612\n",
            "no_improvement_steps:  0\n",
            "step = 6200: loss = 0.18055734038352966\n",
            "step = 6200: Average Return = 0.03999999910593033\n",
            "no_improvement_steps:  0\n",
            "step = 6400: loss = 0.0546477809548378\n",
            "step = 6400: Average Return = 0.2199999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 6600: loss = 0.09378641098737717\n",
            "step = 6600: Average Return = 0.0\n",
            "no_improvement_steps:  0\n",
            "step = 6800: loss = 0.01883883774280548\n",
            "step = 6800: Average Return = 0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 7000: loss = 0.1253964751958847\n",
            "step = 7000: Average Return = 0.2800000011920929\n",
            "no_improvement_steps:  0\n",
            "step = 7200: loss = 0.07829883694648743\n",
            "step = 7200: Average Return = -0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 7400: loss = 0.04868405684828758\n",
            "step = 7400: Average Return = 0.2199999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 7600: loss = 0.17753684520721436\n",
            "step = 7600: Average Return = -0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 7800: loss = 0.11993148922920227\n",
            "step = 7800: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 8000: loss = 0.11797021329402924\n",
            "step = 8000: Average Return = -0.07999999821186066\n",
            "no_improvement_steps:  0\n",
            "step = 8200: loss = 0.13789120316505432\n",
            "step = 8200: Average Return = 0.1599999964237213\n",
            "no_improvement_steps:  0\n",
            "step = 8400: loss = 0.0724075436592102\n",
            "step = 8400: Average Return = 0.14000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 8600: loss = 0.1547623872756958\n",
            "step = 8600: Average Return = 0.2199999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 8800: loss = 0.06074875593185425\n",
            "step = 8800: Average Return = 0.10000000149011612\n",
            "no_improvement_steps:  0\n",
            "step = 9000: loss = 0.06807289272546768\n",
            "step = 9000: Average Return = 0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 9200: loss = 0.15368583798408508\n",
            "step = 9200: Average Return = -0.25999999046325684\n",
            "no_improvement_steps:  0\n",
            "step = 9400: loss = 0.024793554097414017\n",
            "step = 9400: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 9600: loss = 0.05220638960599899\n",
            "step = 9600: Average Return = 0.20000000298023224\n",
            "no_improvement_steps:  0\n",
            "step = 9800: loss = 0.16651999950408936\n",
            "step = 9800: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 10000: loss = 0.1805005967617035\n",
            "step = 10000: Average Return = 0.3400000035762787\n",
            "no_improvement_steps:  0\n",
            "step = 10200: loss = 0.14472904801368713\n",
            "step = 10200: Average Return = 0.25999999046325684\n",
            "no_improvement_steps:  0\n",
            "step = 10400: loss = 0.11794950067996979\n",
            "step = 10400: Average Return = 0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 10600: loss = 0.21804989874362946\n",
            "step = 10600: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 10800: loss = 0.13234348595142365\n",
            "step = 10800: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 11000: loss = 0.1340619921684265\n",
            "step = 11000: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 11200: loss = 0.07393111288547516\n",
            "step = 11200: Average Return = 0.14000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 11400: loss = 0.04892042651772499\n",
            "step = 11400: Average Return = 0.20000000298023224\n",
            "no_improvement_steps:  0\n",
            "step = 11600: loss = 0.12904693186283112\n",
            "step = 11600: Average Return = 0.3400000035762787\n",
            "no_improvement_steps:  0\n",
            "step = 11800: loss = 0.11504092067480087\n",
            "step = 11800: Average Return = 0.05999999865889549\n",
            "no_improvement_steps:  0\n",
            "step = 12000: loss = 0.1450500786304474\n",
            "step = 12000: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 12200: loss = 0.09083465486764908\n",
            "step = 12200: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 12400: loss = 0.012600980699062347\n",
            "step = 12400: Average Return = -0.05999999865889549\n",
            "no_improvement_steps:  0\n",
            "step = 12600: loss = 0.08115790784358978\n",
            "step = 12600: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 12800: loss = 0.09769003093242645\n",
            "step = 12800: Average Return = 0.20000000298023224\n",
            "no_improvement_steps:  0\n",
            "step = 13000: loss = 0.2998034954071045\n",
            "step = 13000: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 13200: loss = 0.1129622757434845\n",
            "step = 13200: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 13400: loss = 0.17409618198871613\n",
            "step = 13400: Average Return = -0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 13600: loss = 0.1716202199459076\n",
            "step = 13600: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 13800: loss = 0.18535883724689484\n",
            "step = 13800: Average Return = 0.25999999046325684\n",
            "no_improvement_steps:  0\n",
            "step = 14000: loss = 0.13575802743434906\n",
            "step = 14000: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 14200: loss = 0.13212455809116364\n",
            "step = 14200: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 14400: loss = 0.057766929268836975\n",
            "step = 14400: Average Return = 0.2800000011920929\n",
            "no_improvement_steps:  0\n",
            "step = 14600: loss = 0.07015540450811386\n",
            "step = 14600: Average Return = 0.699999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 14800: loss = 0.18582536280155182\n",
            "step = 14800: Average Return = 0.25999999046325684\n",
            "no_improvement_steps:  0\n",
            "step = 15000: loss = 0.0702783614397049\n",
            "step = 15000: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 15200: loss = 0.1649705469608307\n",
            "step = 15200: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 15400: loss = 0.05001101270318031\n",
            "step = 15400: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 15600: loss = 0.05645778030157089\n",
            "step = 15600: Average Return = 0.3799999952316284\n",
            "no_improvement_steps:  0\n",
            "step = 15800: loss = 0.16692249476909637\n",
            "step = 15800: Average Return = -0.019999999552965164\n",
            "no_improvement_steps:  0\n",
            "step = 16000: loss = 0.04228251054883003\n",
            "step = 16000: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 16200: loss = 0.13500674068927765\n",
            "step = 16200: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 16400: loss = 0.09011479467153549\n",
            "step = 16400: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 16600: loss = 0.16320134699344635\n",
            "step = 16600: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 16800: loss = 0.1329822689294815\n",
            "step = 16800: Average Return = 0.3799999952316284\n",
            "no_improvement_steps:  0\n",
            "step = 17000: loss = 0.10677039623260498\n",
            "step = 17000: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 17200: loss = 0.0480901338160038\n",
            "step = 17200: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 17400: loss = 0.10945069044828415\n",
            "step = 17400: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 17600: loss = 0.0978306382894516\n",
            "step = 17600: Average Return = 0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 17800: loss = 0.09078606963157654\n",
            "step = 17800: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 18000: loss = 0.1072058454155922\n",
            "step = 18000: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 18200: loss = 0.11948035657405853\n",
            "step = 18200: Average Return = 0.3799999952316284\n",
            "no_improvement_steps:  0\n",
            "step = 18400: loss = 0.015491560101509094\n",
            "step = 18400: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 18600: loss = 0.009258884005248547\n",
            "step = 18600: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 18800: loss = 0.015274322591722012\n",
            "step = 18800: Average Return = 0.14000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 19000: loss = 0.0541544109582901\n",
            "step = 19000: Average Return = 0.10000000149011612\n",
            "no_improvement_steps:  0\n",
            "step = 19200: loss = 0.13909849524497986\n",
            "step = 19200: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 19400: loss = 0.09498204290866852\n",
            "step = 19400: Average Return = -0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 19600: loss = 0.15231482684612274\n",
            "step = 19600: Average Return = 0.20000000298023224\n",
            "no_improvement_steps:  0\n",
            "step = 19800: loss = 0.14059051871299744\n",
            "step = 19800: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 20000: loss = 0.06105315685272217\n",
            "step = 20000: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 20200: loss = 0.15366104245185852\n",
            "step = 20200: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 20400: loss = 0.014726018533110619\n",
            "step = 20400: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 20600: loss = 0.14410528540611267\n",
            "step = 20600: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 20800: loss = 0.14039820432662964\n",
            "step = 20800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 21000: loss = 0.08936814963817596\n",
            "step = 21000: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 21200: loss = 0.0901385024189949\n",
            "step = 21200: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 21400: loss = 0.14079099893569946\n",
            "step = 21400: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 21600: loss = 0.007956210523843765\n",
            "step = 21600: Average Return = -0.019999999552965164\n",
            "no_improvement_steps:  0\n",
            "step = 21800: loss = 0.09928634762763977\n",
            "step = 21800: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 22000: loss = 0.11870210617780685\n",
            "step = 22000: Average Return = 0.23999999463558197\n",
            "no_improvement_steps:  0\n",
            "step = 22200: loss = 0.006320449523627758\n",
            "step = 22200: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 22400: loss = 0.263142466545105\n",
            "step = 22400: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 22600: loss = 0.08303463459014893\n",
            "step = 22600: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 22800: loss = 0.09578777849674225\n",
            "step = 22800: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 23000: loss = 0.19028902053833008\n",
            "step = 23000: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 23200: loss = 0.04202931374311447\n",
            "step = 23200: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 23400: loss = 0.10745567083358765\n",
            "step = 23400: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 23600: loss = 0.10401880741119385\n",
            "step = 23600: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 23800: loss = 0.04159533232450485\n",
            "step = 23800: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 24000: loss = 0.05726462975144386\n",
            "step = 24000: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 24200: loss = 0.009479135274887085\n",
            "step = 24200: Average Return = 0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 24400: loss = 0.013407672755420208\n",
            "step = 24400: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 24600: loss = 0.15262874960899353\n",
            "step = 24600: Average Return = 0.23999999463558197\n",
            "no_improvement_steps:  0\n",
            "step = 24800: loss = 0.16113553941249847\n",
            "step = 24800: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 25000: loss = 0.05298420414328575\n",
            "step = 25000: Average Return = 0.2800000011920929\n",
            "no_improvement_steps:  0\n",
            "step = 25200: loss = 0.06644122302532196\n",
            "step = 25200: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 25400: loss = 0.12136147916316986\n",
            "step = 25400: Average Return = 0.3799999952316284\n",
            "no_improvement_steps:  0\n",
            "step = 25600: loss = 0.20117367804050446\n",
            "step = 25600: Average Return = 0.2800000011920929\n",
            "no_improvement_steps:  0\n",
            "step = 25800: loss = 0.016510527580976486\n",
            "step = 25800: Average Return = 0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 26000: loss = 0.013756012544035912\n",
            "step = 26000: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 26200: loss = 0.17090211808681488\n",
            "step = 26200: Average Return = 0.3400000035762787\n",
            "no_improvement_steps:  0\n",
            "step = 26400: loss = 0.09568092226982117\n",
            "step = 26400: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 26600: loss = 0.14278072118759155\n",
            "step = 26600: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 26800: loss = 0.10980965942144394\n",
            "step = 26800: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 27000: loss = 0.101015605032444\n",
            "step = 27000: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 27200: loss = 0.11362861096858978\n",
            "step = 27200: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 27400: loss = 0.15236297249794006\n",
            "step = 27400: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 27600: loss = 0.1742841899394989\n",
            "step = 27600: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 27800: loss = 0.0484333261847496\n",
            "step = 27800: Average Return = 0.03999999910593033\n",
            "no_improvement_steps:  0\n",
            "step = 28000: loss = 0.18351763486862183\n",
            "step = 28000: Average Return = 0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 28200: loss = 0.00703514413908124\n",
            "step = 28200: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 28400: loss = 0.12195496261119843\n",
            "step = 28400: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 28600: loss = 0.1093611791729927\n",
            "step = 28600: Average Return = 0.3400000035762787\n",
            "no_improvement_steps:  0\n",
            "step = 28800: loss = 0.012792710214853287\n",
            "step = 28800: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 29000: loss = 0.09231802821159363\n",
            "step = 29000: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 29200: loss = 0.013236640952527523\n",
            "step = 29200: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 29400: loss = 0.11207488179206848\n",
            "step = 29400: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 29600: loss = 0.11807269603013992\n",
            "step = 29600: Average Return = 0.20000000298023224\n",
            "no_improvement_steps:  0\n",
            "step = 29800: loss = 0.05859362706542015\n",
            "step = 29800: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 30000: loss = 0.1276654601097107\n",
            "step = 30000: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 30200: loss = 0.0917038545012474\n",
            "step = 30200: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 30400: loss = 0.07806705683469772\n",
            "step = 30400: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 30600: loss = 0.07852013409137726\n",
            "step = 30600: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 30800: loss = 0.0878983587026596\n",
            "step = 30800: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 31000: loss = 0.00825086236000061\n",
            "step = 31000: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 31200: loss = 0.009284347295761108\n",
            "step = 31200: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 31400: loss = 0.014505982398986816\n",
            "step = 31400: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 31600: loss = 0.0534076988697052\n",
            "step = 31600: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 31800: loss = 0.15211421251296997\n",
            "step = 31800: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 32000: loss = 0.05259034410119057\n",
            "step = 32000: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 32200: loss = 0.009139223955571651\n",
            "step = 32200: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 32400: loss = 0.012153994292020798\n",
            "step = 32400: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 32600: loss = 0.13154952228069305\n",
            "step = 32600: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 32800: loss = 0.1920013278722763\n",
            "step = 32800: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 33000: loss = 0.010822495445609093\n",
            "step = 33000: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 33200: loss = 0.10846619307994843\n",
            "step = 33200: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 33400: loss = 0.0562642440199852\n",
            "step = 33400: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 33600: loss = 0.05311408266425133\n",
            "step = 33600: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 33800: loss = 0.10427418351173401\n",
            "step = 33800: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 34000: loss = 0.1069650948047638\n",
            "step = 34000: Average Return = 0.699999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 34200: loss = 0.14034713804721832\n",
            "step = 34200: Average Return = 0.699999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 34400: loss = 0.13721458613872528\n",
            "step = 34400: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 34600: loss = 0.057634953409433365\n",
            "step = 34600: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 34800: loss = 0.05557576194405556\n",
            "step = 34800: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 35000: loss = 0.04583432897925377\n",
            "step = 35000: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 35200: loss = 0.05461827665567398\n",
            "step = 35200: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 35400: loss = 0.00793306902050972\n",
            "step = 35400: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 35600: loss = 0.05401936173439026\n",
            "step = 35600: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 35800: loss = 0.05272694677114487\n",
            "step = 35800: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 36000: loss = 0.2579951882362366\n",
            "step = 36000: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 36200: loss = 0.0930585041642189\n",
            "step = 36200: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 36400: loss = 0.09289701282978058\n",
            "step = 36400: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 36600: loss = 0.09477115422487259\n",
            "step = 36600: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 36800: loss = 0.045078013092279434\n",
            "step = 36800: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 37000: loss = 0.04258514195680618\n",
            "step = 37000: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 37200: loss = 0.10392841696739197\n",
            "step = 37200: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 37400: loss = 0.053935837000608444\n",
            "step = 37400: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 37600: loss = 0.10297676920890808\n",
            "step = 37600: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 37800: loss = 0.06384241580963135\n",
            "step = 37800: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 38000: loss = 0.09956060349941254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`0/step_type` is not a valid tf.function parameter name. Sanitizing to `arg_0_step_type`.\n",
            "WARNING:absl:`0/reward` is not a valid tf.function parameter name. Sanitizing to `arg_0_reward`.\n",
            "WARNING:absl:`0/discount` is not a valid tf.function parameter name. Sanitizing to `arg_0_discount`.\n",
            "WARNING:absl:`0/observation/action_mask` is not a valid tf.function parameter name. Sanitizing to `arg_0_observation_action_mask`.\n",
            "WARNING:absl:`0/observation/observation` is not a valid tf.function parameter name. Sanitizing to `arg_0_observation_observation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 38000: Average Return = 0.7200000286102295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no_improvement_steps:  0\n",
            "step = 38200: loss = 0.1102057546377182\n",
            "step = 38200: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 38400: loss = 0.009050652384757996\n",
            "step = 38400: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 38600: loss = 0.14855659008026123\n",
            "step = 38600: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 38800: loss = 0.1304825097322464\n",
            "step = 38800: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 39000: loss = 0.10490722954273224\n",
            "step = 39000: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 39200: loss = 0.08651342242956161\n",
            "step = 39200: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 39400: loss = 0.13090921938419342\n",
            "step = 39400: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 39600: loss = 0.2088484764099121\n",
            "step = 39600: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 39800: loss = 0.05598103627562523\n",
            "step = 39800: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 40000: loss = 0.09211912751197815\n",
            "step = 40000: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 40200: loss = 0.04841803014278412\n",
            "step = 40200: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 40400: loss = 0.048600487411022186\n",
            "step = 40400: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 40600: loss = 0.08368931710720062\n",
            "step = 40600: Average Return = 0.23999999463558197\n",
            "no_improvement_steps:  0\n",
            "step = 40800: loss = 0.08030810952186584\n",
            "step = 40800: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 41000: loss = 0.10970164835453033\n",
            "step = 41000: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 41200: loss = 0.005436642561107874\n",
            "step = 41200: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 41400: loss = 0.11280618607997894\n",
            "step = 41400: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 41600: loss = 0.006475646048784256\n",
            "step = 41600: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 41800: loss = 0.05102600157260895\n",
            "step = 41800: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 42000: loss = 0.005713103339076042\n",
            "step = 42000: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 42200: loss = 0.10660593211650848\n",
            "step = 42200: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 42400: loss = 0.09278841316699982\n",
            "step = 42400: Average Return = 0.3400000035762787\n",
            "no_improvement_steps:  0\n",
            "step = 42600: loss = 0.05865887925028801\n",
            "step = 42600: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 42800: loss = 0.15386627614498138\n",
            "step = 42800: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 43000: loss = 0.008369779214262962\n",
            "step = 43000: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 43200: loss = 0.14217229187488556\n",
            "step = 43200: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 43400: loss = 0.06088225916028023\n",
            "step = 43400: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 43600: loss = 0.006498607341200113\n",
            "step = 43600: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 43800: loss = 0.0535564199090004\n",
            "step = 43800: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 44000: loss = 0.13387855887413025\n",
            "step = 44000: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 44200: loss = 0.10600785911083221\n",
            "step = 44200: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 44400: loss = 0.04695257171988487\n",
            "step = 44400: Average Return = 0.2199999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 44600: loss = 0.0917668268084526\n",
            "step = 44600: Average Return = 0.3400000035762787\n",
            "no_improvement_steps:  0\n",
            "step = 44800: loss = 0.0637601837515831\n",
            "step = 44800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 45000: loss = 0.08858474344015121\n",
            "step = 45000: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 45200: loss = 0.008110146969556808\n",
            "step = 45200: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 45400: loss = 0.11422677338123322\n",
            "step = 45400: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 45600: loss = 0.05608496814966202\n",
            "step = 45600: Average Return = 0.23999999463558197\n",
            "no_improvement_steps:  0\n",
            "step = 45800: loss = 0.0594395287334919\n",
            "step = 45800: Average Return = 0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 46000: loss = 0.15422353148460388\n",
            "step = 46000: Average Return = 0.3799999952316284\n",
            "no_improvement_steps:  0\n",
            "step = 46200: loss = 0.045404102653265\n",
            "step = 46200: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 46400: loss = 0.0537000373005867\n",
            "step = 46400: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 46600: loss = 0.054300665855407715\n",
            "step = 46600: Average Return = 0.25999999046325684\n",
            "no_improvement_steps:  0\n",
            "step = 46800: loss = 0.008186481893062592\n",
            "step = 46800: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 47000: loss = 0.10192984342575073\n",
            "step = 47000: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 47200: loss = 0.05256446823477745\n",
            "step = 47200: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 47400: loss = 0.14438748359680176\n",
            "step = 47400: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 47600: loss = 0.09885713458061218\n",
            "step = 47600: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 47800: loss = 0.05432699993252754\n",
            "step = 47800: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 48000: loss = 0.14365142583847046\n",
            "step = 48000: Average Return = 0.3799999952316284\n",
            "no_improvement_steps:  0\n",
            "step = 48200: loss = 0.006287109572440386\n",
            "step = 48200: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 48400: loss = 0.04779164493083954\n",
            "step = 48400: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 48600: loss = 0.05856020748615265\n",
            "step = 48600: Average Return = 0.07999999821186066\n",
            "no_improvement_steps:  0\n",
            "step = 48800: loss = 0.1321977972984314\n",
            "step = 48800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 49000: loss = 0.005510766990482807\n",
            "step = 49000: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 49200: loss = 0.009625431150197983\n",
            "step = 49200: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 49400: loss = 0.012185519561171532\n",
            "step = 49400: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 49600: loss = 0.14964799582958221\n",
            "step = 49600: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 49800: loss = 0.051978908479213715\n",
            "step = 49800: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 50000: loss = 0.12560413777828217\n",
            "step = 50000: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 50200: loss = 0.09230460226535797\n",
            "step = 50200: Average Return = 0.699999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 50400: loss = 0.0056753503158688545\n",
            "step = 50400: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 50600: loss = 0.12157437205314636\n",
            "step = 50600: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 50800: loss = 0.21110136806964874\n",
            "step = 50800: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 51000: loss = 0.04233254864811897\n",
            "step = 51000: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 51200: loss = 0.00661774817854166\n",
            "step = 51200: Average Return = 0.699999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 51400: loss = 0.10152323544025421\n",
            "step = 51400: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 51600: loss = 0.16469822824001312\n",
            "step = 51600: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 51800: loss = 0.09853599965572357\n",
            "step = 51800: Average Return = 0.25999999046325684\n",
            "no_improvement_steps:  0\n",
            "step = 52000: loss = 0.056783527135849\n",
            "step = 52000: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 52200: loss = 0.05973121151328087\n",
            "step = 52200: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 52400: loss = 0.05032755434513092\n",
            "step = 52400: Average Return = 0.1599999964237213\n",
            "no_improvement_steps:  0\n",
            "step = 52600: loss = 0.10029822587966919\n",
            "step = 52600: Average Return = 0.7200000286102295\n",
            "no_improvement_steps:  0\n",
            "step = 52800: loss = 0.14269989728927612\n",
            "step = 52800: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 53000: loss = 0.050329532474279404\n",
            "step = 53000: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 53200: loss = 0.15610001981258392\n",
            "step = 53200: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 53400: loss = 0.009099701419472694\n",
            "step = 53400: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 53600: loss = 0.06898407638072968\n",
            "step = 53600: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 53800: loss = 0.005946359597146511\n",
            "step = 53800: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 54000: loss = 0.007576705887913704\n",
            "step = 54000: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 54200: loss = 0.10709728300571442\n",
            "step = 54200: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 54400: loss = 0.1586802899837494\n",
            "step = 54400: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 54600: loss = 0.053279049694538116\n",
            "step = 54600: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 54800: loss = 0.056548573076725006\n",
            "step = 54800: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 55000: loss = 0.053241461515426636\n",
            "step = 55000: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 55200: loss = 0.007047475315630436\n",
            "step = 55200: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 55400: loss = 0.06095997244119644\n",
            "step = 55400: Average Return = -0.019999999552965164\n",
            "no_improvement_steps:  0\n",
            "step = 55600: loss = 0.007607403211295605\n",
            "step = 55600: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 55800: loss = 0.10344351083040237\n",
            "step = 55800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 56000: loss = 0.05575050041079521\n",
            "step = 56000: Average Return = 0.7599999904632568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no_improvement_steps:  0\n",
            "step = 56200: loss = 0.09664194285869598\n",
            "step = 56200: Average Return = 0.8199999928474426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no_improvement_steps:  0\n",
            "step = 56400: loss = 0.046276867389678955\n",
            "step = 56400: Average Return = 0.7400000095367432\n",
            "no_improvement_steps:  0\n",
            "step = 56600: loss = 0.2177429348230362\n",
            "step = 56600: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 56800: loss = 0.11852476000785828\n",
            "step = 56800: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 57000: loss = 0.10550844669342041\n",
            "step = 57000: Average Return = 0.10000000149011612\n",
            "no_improvement_steps:  0\n",
            "step = 57200: loss = 0.05902019143104553\n",
            "step = 57200: Average Return = 0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 57400: loss = 0.15682676434516907\n",
            "step = 57400: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 57600: loss = 0.14163729548454285\n",
            "step = 57600: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 57800: loss = 0.23696880042552948\n",
            "step = 57800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 58000: loss = 0.05521861091256142\n",
            "step = 58000: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 58200: loss = 0.009202326647937298\n",
            "step = 58200: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 58400: loss = 0.14823974668979645\n",
            "step = 58400: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 58600: loss = 0.18028494715690613\n",
            "step = 58600: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 58800: loss = 0.09170067310333252\n",
            "step = 58800: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 59000: loss = 0.05018499121069908\n",
            "step = 59000: Average Return = 0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 59200: loss = 0.14833831787109375\n",
            "step = 59200: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 59400: loss = 0.008330658078193665\n",
            "step = 59400: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 59600: loss = 0.10901494324207306\n",
            "step = 59600: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 59800: loss = 0.2020346075296402\n",
            "step = 59800: Average Return = 0.1599999964237213\n",
            "no_improvement_steps:  0\n",
            "step = 60000: loss = 0.14283187687397003\n",
            "step = 60000: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 60200: loss = 0.0032797600142657757\n",
            "step = 60200: Average Return = 0.25999999046325684\n",
            "no_improvement_steps:  0\n",
            "step = 60400: loss = 0.1271701157093048\n",
            "step = 60400: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 60600: loss = 0.09081988781690598\n",
            "step = 60600: Average Return = 0.2800000011920929\n",
            "no_improvement_steps:  0\n",
            "step = 60800: loss = 0.011715981177985668\n",
            "step = 60800: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 61000: loss = 0.07300195842981339\n",
            "step = 61000: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 61200: loss = 0.20177516341209412\n",
            "step = 61200: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 61400: loss = 0.050298649817705154\n",
            "step = 61400: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 61600: loss = 0.048732854425907135\n",
            "step = 61600: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 61800: loss = 0.0936402976512909\n",
            "step = 61800: Average Return = 0.7200000286102295\n",
            "no_improvement_steps:  0\n",
            "step = 62000: loss = 0.04414505511522293\n",
            "step = 62000: Average Return = 0.7400000095367432\n",
            "no_improvement_steps:  0\n",
            "step = 62200: loss = 0.06112441048026085\n",
            "step = 62200: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 62400: loss = 0.007959326729178429\n",
            "step = 62400: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 62600: loss = 0.048146430402994156\n",
            "step = 62600: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 62800: loss = 0.1008189469575882\n",
            "step = 62800: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 63000: loss = 0.10636080056428909\n",
            "step = 63000: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 63200: loss = 0.04148159548640251\n",
            "step = 63200: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 63400: loss = 0.042267873883247375\n",
            "step = 63400: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 63600: loss = 0.10670758038759232\n",
            "step = 63600: Average Return = 0.699999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 63800: loss = 0.05902085825800896\n",
            "step = 63800: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 64000: loss = 0.11206845194101334\n",
            "step = 64000: Average Return = 0.7799999713897705\n",
            "no_improvement_steps:  0\n",
            "step = 64200: loss = 0.0527154877781868\n",
            "step = 64200: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 64400: loss = 0.05912598967552185\n",
            "step = 64400: Average Return = 0.7200000286102295\n",
            "no_improvement_steps:  0\n",
            "step = 64600: loss = 0.008452411741018295\n",
            "step = 64600: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 64800: loss = 0.007727019488811493\n",
            "step = 64800: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 65000: loss = 0.06988264620304108\n",
            "step = 65000: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 65200: loss = 0.050093017518520355\n",
            "step = 65200: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 65400: loss = 0.0519355870783329\n",
            "step = 65400: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 65600: loss = 0.007682177238166332\n",
            "step = 65600: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 65800: loss = 0.05366457998752594\n",
            "step = 65800: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 66000: loss = 0.16740630567073822\n",
            "step = 66000: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 66200: loss = 0.09751279652118683\n",
            "step = 66200: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 66400: loss = 0.009088768623769283\n",
            "step = 66400: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 66600: loss = 0.1000514104962349\n",
            "step = 66600: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 66800: loss = 0.10171213746070862\n",
            "step = 66800: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 67000: loss = 0.010530410334467888\n",
            "step = 67000: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 67200: loss = 0.10114926844835281\n",
            "step = 67200: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 67400: loss = 0.12085951864719391\n",
            "step = 67400: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 67600: loss = 0.007730450481176376\n",
            "step = 67600: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 67800: loss = 0.00534813990816474\n",
            "step = 67800: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 68000: loss = 0.08853904902935028\n",
            "step = 68000: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 68200: loss = 0.2063763588666916\n",
            "step = 68200: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 68400: loss = 0.006040860433131456\n",
            "step = 68400: Average Return = 0.3799999952316284\n",
            "no_improvement_steps:  0\n",
            "step = 68600: loss = 0.0548604354262352\n",
            "step = 68600: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 68800: loss = 0.05131160095334053\n",
            "step = 68800: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 69000: loss = 0.1669120192527771\n",
            "step = 69000: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 69200: loss = 0.007972804829478264\n",
            "step = 69200: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 69400: loss = 0.058484286069869995\n",
            "step = 69400: Average Return = 0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 69600: loss = 0.05266781896352768\n",
            "step = 69600: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 69800: loss = 0.09907204657793045\n",
            "step = 69800: Average Return = 0.25999999046325684\n",
            "no_improvement_steps:  0\n",
            "step = 70000: loss = 0.10708889365196228\n",
            "step = 70000: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 70200: loss = 0.04843346029520035\n",
            "step = 70200: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 70400: loss = 0.14003847539424896\n",
            "step = 70400: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 70600: loss = 0.00873776525259018\n",
            "step = 70600: Average Return = 0.3799999952316284\n",
            "no_improvement_steps:  0\n",
            "step = 70800: loss = 0.1838333159685135\n",
            "step = 70800: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 71000: loss = 0.0072493357583880424\n",
            "step = 71000: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 71200: loss = 0.0504419319331646\n",
            "step = 71200: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 71400: loss = 0.09878990054130554\n",
            "step = 71400: Average Return = 0.2800000011920929\n",
            "no_improvement_steps:  0\n",
            "step = 71600: loss = 0.007107787299901247\n",
            "step = 71600: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 71800: loss = 0.006881529465317726\n",
            "step = 71800: Average Return = 0.7200000286102295\n",
            "no_improvement_steps:  0\n",
            "step = 72000: loss = 0.057805825024843216\n",
            "step = 72000: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 72200: loss = 0.008015990257263184\n",
            "step = 72200: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 72400: loss = 0.19975337386131287\n",
            "step = 72400: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 72600: loss = 0.005431883968412876\n",
            "step = 72600: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 72800: loss = 0.05880403518676758\n",
            "step = 72800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 73000: loss = 0.16098752617835999\n",
            "step = 73000: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 73200: loss = 0.06134505569934845\n",
            "step = 73200: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 73400: loss = 0.010461864061653614\n",
            "step = 73400: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 73600: loss = 0.0451943539083004\n",
            "step = 73600: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 73800: loss = 0.09142646193504333\n",
            "step = 73800: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 74000: loss = 0.13954398036003113\n",
            "step = 74000: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 74200: loss = 0.13712532818317413\n",
            "step = 74200: Average Return = 0.7799999713897705\n",
            "no_improvement_steps:  0\n",
            "step = 74400: loss = 0.006509896367788315\n",
            "step = 74400: Average Return = 0.7400000095367432\n",
            "no_improvement_steps:  0\n",
            "step = 74600: loss = 0.04667967930436134\n",
            "step = 74600: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 74800: loss = 0.20275916159152985\n",
            "step = 74800: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 75000: loss = 0.004780514165759087\n",
            "step = 75000: Average Return = 0.11999999731779099\n",
            "no_improvement_steps:  0\n",
            "step = 75200: loss = 0.13156262040138245\n",
            "step = 75200: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 75400: loss = 0.1502852737903595\n",
            "step = 75400: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 75600: loss = 0.006292079575359821\n",
            "step = 75600: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 75800: loss = 0.054567404091358185\n",
            "step = 75800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 76000: loss = 0.12736225128173828\n",
            "step = 76000: Average Return = 0.7799999713897705\n",
            "no_improvement_steps:  0\n",
            "step = 76200: loss = 0.0066314563155174255\n",
            "step = 76200: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 76400: loss = 0.19814303517341614\n",
            "step = 76400: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 76600: loss = 0.053505852818489075\n",
            "step = 76600: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 76800: loss = 0.005351053550839424\n",
            "step = 76800: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 77000: loss = 0.010362310335040092\n",
            "step = 77000: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 77200: loss = 0.05912327766418457\n",
            "step = 77200: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 77400: loss = 0.11252538859844208\n",
            "step = 77400: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 77600: loss = 0.09344816952943802\n",
            "step = 77600: Average Return = 0.23999999463558197\n",
            "no_improvement_steps:  0\n",
            "step = 77800: loss = 0.007975282147526741\n",
            "step = 77800: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 78000: loss = 0.10470843315124512\n",
            "step = 78000: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 78200: loss = 0.006516206078231335\n",
            "step = 78200: Average Return = 0.7799999713897705\n",
            "no_improvement_steps:  0\n",
            "step = 78400: loss = 0.052167315036058426\n",
            "step = 78400: Average Return = 0.3199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 78600: loss = 0.059045836329460144\n",
            "step = 78600: Average Return = 0.7400000095367432\n",
            "no_improvement_steps:  0\n",
            "step = 78800: loss = 0.05463681370019913\n",
            "step = 78800: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 79000: loss = 0.05264480412006378\n",
            "step = 79000: Average Return = 0.7200000286102295\n",
            "no_improvement_steps:  0\n",
            "step = 79200: loss = 0.09332475811243057\n",
            "step = 79200: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 79400: loss = 0.0048887478187680244\n",
            "step = 79400: Average Return = 0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 79600: loss = 0.10231136530637741\n",
            "step = 79600: Average Return = 0.699999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 79800: loss = 0.05270262435078621\n",
            "step = 79800: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 80000: loss = 0.008209461346268654\n",
            "step = 80000: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 80200: loss = 0.1011660173535347\n",
            "step = 80200: Average Return = 0.20000000298023224\n",
            "no_improvement_steps:  0\n",
            "step = 80400: loss = 0.05381089821457863\n",
            "step = 80400: Average Return = 0.3400000035762787\n",
            "no_improvement_steps:  0\n",
            "step = 80600: loss = 0.01170380599796772\n",
            "step = 80600: Average Return = 0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 80800: loss = 0.05240743234753609\n",
            "step = 80800: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 81000: loss = 0.11633492261171341\n",
            "step = 81000: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 81200: loss = 0.0052397530525922775\n",
            "step = 81200: Average Return = 0.3799999952316284\n",
            "no_improvement_steps:  0\n",
            "step = 81400: loss = 0.009435431100428104\n",
            "step = 81400: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 81600: loss = 0.01015697792172432\n",
            "step = 81600: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 81800: loss = 0.10543233901262283\n",
            "step = 81800: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 82000: loss = 0.05605239421129227\n",
            "step = 82000: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 82200: loss = 0.12233201414346695\n",
            "step = 82200: Average Return = 0.7200000286102295\n",
            "no_improvement_steps:  0\n",
            "step = 82400: loss = 0.008219342678785324\n",
            "step = 82400: Average Return = 0.3400000035762787\n",
            "no_improvement_steps:  0\n",
            "step = 82600: loss = 0.08525583148002625\n",
            "step = 82600: Average Return = 0.2800000011920929\n",
            "no_improvement_steps:  0\n",
            "step = 82800: loss = 0.05087662488222122\n",
            "step = 82800: Average Return = 0.18000000715255737\n",
            "no_improvement_steps:  0\n",
            "step = 83000: loss = 0.005745207890868187\n",
            "step = 83000: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 83200: loss = 0.05295310169458389\n",
            "step = 83200: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 83400: loss = 0.05400199815630913\n",
            "step = 83400: Average Return = 0.20000000298023224\n",
            "no_improvement_steps:  0\n",
            "step = 83600: loss = 0.008413413539528847\n",
            "step = 83600: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 83800: loss = 0.0053200265392661095\n",
            "step = 83800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 84000: loss = 0.005091849714517593\n",
            "step = 84000: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 84200: loss = 0.150915265083313\n",
            "step = 84200: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 84400: loss = 0.00912942923605442\n",
            "step = 84400: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 84600: loss = 0.06213420256972313\n",
            "step = 84600: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 84800: loss = 0.057706378400325775\n",
            "step = 84800: Average Return = 0.7400000095367432\n",
            "no_improvement_steps:  0\n",
            "step = 85000: loss = 0.15515825152397156\n",
            "step = 85000: Average Return = 0.36000001430511475\n",
            "no_improvement_steps:  0\n",
            "step = 85200: loss = 0.003973959479480982\n",
            "step = 85200: Average Return = 0.30000001192092896\n",
            "no_improvement_steps:  0\n",
            "step = 85400: loss = 0.053902916610240936\n",
            "step = 85400: Average Return = 0.2800000011920929\n",
            "no_improvement_steps:  0\n",
            "step = 85600: loss = 0.04947562515735626\n",
            "step = 85600: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 85800: loss = 0.006173357367515564\n",
            "step = 85800: Average Return = 0.20000000298023224\n",
            "no_improvement_steps:  0\n",
            "step = 86000: loss = 0.07361800968647003\n",
            "step = 86000: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 86200: loss = 0.14012780785560608\n",
            "step = 86200: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 86400: loss = 0.04976267367601395\n",
            "step = 86400: Average Return = 0.14000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 86600: loss = 0.10909943282604218\n",
            "step = 86600: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 86800: loss = 0.009005937725305557\n",
            "step = 86800: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 87000: loss = 0.08713842183351517\n",
            "step = 87000: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 87200: loss = 0.21111613512039185\n",
            "step = 87200: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 87400: loss = 0.08446487039327621\n",
            "step = 87400: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 87600: loss = 0.16290366649627686\n",
            "step = 87600: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 87800: loss = 0.052341312170028687\n",
            "step = 87800: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 88000: loss = 0.10045260936021805\n",
            "step = 88000: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 88200: loss = 0.05531074106693268\n",
            "step = 88200: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 88400: loss = 0.00574827566742897\n",
            "step = 88400: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 88600: loss = 0.10920628905296326\n",
            "step = 88600: Average Return = 0.7599999904632568\n",
            "no_improvement_steps:  0\n",
            "step = 88800: loss = 0.049811553210020065\n",
            "step = 88800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 89000: loss = 0.007229692302644253\n",
            "step = 89000: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 89200: loss = 0.008089796639978886\n",
            "step = 89200: Average Return = 0.3799999952316284\n",
            "no_improvement_steps:  0\n",
            "step = 89400: loss = 0.11677522957324982\n",
            "step = 89400: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 89600: loss = 0.24791398644447327\n",
            "step = 89600: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 89800: loss = 0.05574915185570717\n",
            "step = 89800: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 90000: loss = 0.0061982679180800915\n",
            "step = 90000: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 90200: loss = 0.004688589368015528\n",
            "step = 90200: Average Return = 0.2800000011920929\n",
            "no_improvement_steps:  0\n",
            "step = 90400: loss = 0.1474350392818451\n",
            "step = 90400: Average Return = 0.7799999713897705\n",
            "no_improvement_steps:  0\n",
            "step = 90600: loss = 0.11047562956809998\n",
            "step = 90600: Average Return = 0.23999999463558197\n",
            "no_improvement_steps:  0\n",
            "step = 90800: loss = 0.051287777721881866\n",
            "step = 90800: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 91000: loss = 0.11083962023258209\n",
            "step = 91000: Average Return = 0.7599999904632568\n",
            "no_improvement_steps:  0\n",
            "step = 91200: loss = 0.1490042507648468\n",
            "step = 91200: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 91400: loss = 0.06115332618355751\n",
            "step = 91400: Average Return = 0.4000000059604645\n",
            "no_improvement_steps:  0\n",
            "step = 91600: loss = 0.1939028799533844\n",
            "step = 91600: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 91800: loss = 0.1619827151298523\n",
            "step = 91800: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 92000: loss = 0.10277125239372253\n",
            "step = 92000: Average Return = 0.699999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 92200: loss = 0.2020471841096878\n",
            "step = 92200: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 92400: loss = 0.05961865931749344\n",
            "step = 92400: Average Return = 0.4399999976158142\n",
            "no_improvement_steps:  0\n",
            "step = 92600: loss = 0.09346629679203033\n",
            "step = 92600: Average Return = 0.6399999856948853\n",
            "no_improvement_steps:  0\n",
            "step = 92800: loss = 0.05196032673120499\n",
            "step = 92800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 93000: loss = 0.005631096661090851\n",
            "step = 93000: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 93200: loss = 0.007090520579367876\n",
            "step = 93200: Average Return = 0.6600000262260437\n",
            "no_improvement_steps:  0\n",
            "step = 93400: loss = 0.158796489238739\n",
            "step = 93400: Average Return = 0.5\n",
            "no_improvement_steps:  0\n",
            "step = 93600: loss = 0.0653875395655632\n",
            "step = 93600: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 93800: loss = 0.005996152758598328\n",
            "step = 93800: Average Return = 0.7799999713897705\n",
            "no_improvement_steps:  0\n",
            "step = 94000: loss = 0.04980909079313278\n",
            "step = 94000: Average Return = 0.7599999904632568\n",
            "no_improvement_steps:  0\n",
            "step = 94200: loss = 0.06777430325746536\n",
            "step = 94200: Average Return = 0.5199999809265137\n",
            "no_improvement_steps:  0\n",
            "step = 94400: loss = 0.05761207267642021\n",
            "step = 94400: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 94600: loss = 0.05601659417152405\n",
            "step = 94600: Average Return = 0.23999999463558197\n",
            "no_improvement_steps:  0\n",
            "step = 94800: loss = 0.006517711095511913\n",
            "step = 94800: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 95000: loss = 0.1101212128996849\n",
            "step = 95000: Average Return = 0.41999998688697815\n",
            "no_improvement_steps:  0\n",
            "step = 95200: loss = 0.05219871178269386\n",
            "step = 95200: Average Return = 0.5600000023841858\n",
            "no_improvement_steps:  0\n",
            "step = 95400: loss = 0.11130932718515396\n",
            "step = 95400: Average Return = 0.019999999552965164\n",
            "no_improvement_steps:  0\n",
            "step = 95600: loss = 0.05000278726220131\n",
            "step = 95600: Average Return = 0.47999998927116394\n",
            "no_improvement_steps:  0\n",
            "step = 95800: loss = 0.0059958286583423615\n",
            "step = 95800: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 96000: loss = 0.006701666861772537\n",
            "step = 96000: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 96200: loss = 0.20060788094997406\n",
            "step = 96200: Average Return = 0.7599999904632568\n",
            "no_improvement_steps:  0\n",
            "step = 96400: loss = 0.18793725967407227\n",
            "step = 96400: Average Return = 0.7400000095367432\n",
            "no_improvement_steps:  0\n",
            "step = 96600: loss = 0.013880621641874313\n",
            "step = 96600: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 96800: loss = 0.007861150428652763\n",
            "step = 96800: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 97000: loss = 0.007858826778829098\n",
            "step = 97000: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 97200: loss = 0.005043006036430597\n",
            "step = 97200: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 97400: loss = 0.006699470337480307\n",
            "step = 97400: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 97600: loss = 0.052475348114967346\n",
            "step = 97600: Average Return = 0.5400000214576721\n",
            "no_improvement_steps:  0\n",
            "step = 97800: loss = 0.008891057223081589\n",
            "step = 97800: Average Return = 0.8199999928474426\n",
            "no_improvement_steps:  0\n",
            "step = 98000: loss = 0.007316133007407188\n",
            "step = 98000: Average Return = 0.5799999833106995\n",
            "no_improvement_steps:  0\n",
            "step = 98200: loss = 0.04583469033241272\n",
            "step = 98200: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 98400: loss = 0.057973556220531464\n",
            "step = 98400: Average Return = 0.8399999737739563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no_improvement_steps:  0\n",
            "step = 98600: loss = 0.052058860659599304\n",
            "step = 98600: Average Return = 0.6200000047683716\n",
            "no_improvement_steps:  0\n",
            "step = 98800: loss = 0.006465999409556389\n",
            "step = 98800: Average Return = 0.46000000834465027\n",
            "no_improvement_steps:  0\n",
            "step = 99000: loss = 0.09592690318822861\n",
            "step = 99000: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 99200: loss = 0.006952743045985699\n",
            "step = 99200: Average Return = 0.699999988079071\n",
            "no_improvement_steps:  0\n",
            "step = 99400: loss = 0.16944952309131622\n",
            "step = 99400: Average Return = 0.7599999904632568\n",
            "no_improvement_steps:  0\n",
            "step = 99600: loss = 0.005826987326145172\n",
            "step = 99600: Average Return = 0.6000000238418579\n",
            "no_improvement_steps:  0\n",
            "step = 99800: loss = 0.06673594564199448\n",
            "step = 99800: Average Return = 0.6800000071525574\n",
            "no_improvement_steps:  0\n",
            "step = 100000: loss = 0.10403719544410706\n",
            "step = 100000: Average Return = 0.800000011920929\n",
            "no_improvement_steps:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_policy = tf.saved_model.load(policy_dir)"
      ],
      "metadata": {
        "id": "D9He1Uj9s6ur"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_return = compute_avg_return(eval_env, saved_policy, 5000)"
      ],
      "metadata": {
        "id": "wC5lJb8es9Lk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2u4nbq2eQoa",
        "outputId": "0db46514-724d-4521-85b0-710b7a0fdead"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7564"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_return = compute_avg_return(train_env, saved_policy, 5000)"
      ],
      "metadata": {
        "id": "E-gNrQ9teSAE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_return"
      ],
      "metadata": {
        "id": "CCKzVR_U0wPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb8dff2-027e-40f7-e64b-8976d70a2998"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.742"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = range(0, iter_count + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "#plt.ylim(top=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "WIVpHQGzeTqj",
        "outputId": "7b5643bb-8816-4164-b4cc-11ad8c5fe820"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Iterations')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KNIuFszNF-PS"
      },
      "execution_count": 30,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}